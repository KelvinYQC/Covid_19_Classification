{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cefe5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, datasets,metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,BatchNormalization, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91cfc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the data directory\n",
    "data_address = os.path.join(os.getcwd(),'..', 'Data')\n",
    "image_address = os.path.join(data_address, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset')\n",
    "training_label = pd.read_csv(os.path.join(data_address, 'training_label.csv'))\n",
    "testing_label = pd.read_csv(os.path.join(data_address, 'testing_label.csv'))\n",
    "# Get the image paths\n",
    "train_images_normal = [os.path.join(image_address, 'train', filename) for filename in training_label[training_label.Label == 'Normal'].X_ray_image_name.tolist()]\n",
    "train_images_sick = [os.path.join(image_address, 'train', filename) for filename in training_label[training_label.Label == 'Pnemonia'].X_ray_image_name.tolist()]\n",
    "test_images_normal = [os.path.join(image_address, 'test', filename) for filename in testing_label[testing_label.Label == 'Normal'].X_ray_image_name.tolist()]\n",
    "test_images_sick = [os.path.join(image_address, 'test', filename) for filename in testing_label[testing_label.Label == 'Pnemonia'].X_ray_image_name.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cae2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling parameters\n",
    "train_arrays = []\n",
    "size = (256, 256)\n",
    "batch_size = 32\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,        # Degree range for random rotations\n",
    "    width_shift_range=0.2,    # Range for horizontal shift\n",
    "    height_shift_range=0.2,   # Range for vertical shift\n",
    "    shear_range=0.2,          # Shear intensity range\n",
    "    zoom_range=0.2,           # Range for random zoom\n",
    "    horizontal_flip=True,     # Randomly flip images horizontally\n",
    "    vertical_flip=False       # Do not flip images vertically\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc167f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "training_label.dropna()\n",
    "for x in training_label['X_ray_image_name']:\n",
    "    try:\n",
    "        img_path = os.path.join(image_address, 'train', x)\n",
    "        img = image.load_img(img_path, target_size=size)\n",
    "        img_array = image.img_to_array(img)\n",
    "        train_arrays.append(img_array)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {img_path}\")\n",
    "        # Handle the exception or skip the image if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e24cbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_arrays and label to NumPy arrays\n",
    "train_images = np.array(train_arrays)\n",
    "label_mapping = {\"Pnemonia\": 1, \"Normal\": 0}\n",
    "label = training_label['Label'].map(label_mapping)\n",
    "train_images = train_images.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc4ca846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "augmented_images = datagen.flow(train_images, label, batch_size=batch_size)\n",
    "augmented_train_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "for images, labels in augmented_images:\n",
    "    augmented_train_images.append(images)\n",
    "    augmented_labels.append(labels)\n",
    "    if len(augmented_train_images) >= (len(train_images) / batch_size):\n",
    "        break\n",
    "\n",
    "augmented_train_images = np.concatenate(augmented_train_images)\n",
    "augmented_labels = np.concatenate(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3fa61ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10572,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd93b5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5286, 256, 256, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f693fa24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5286, 256, 256, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a89a888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_images = np.concatenate((train_images, augmented_train_images))\n",
    "labels = np.concatenate((label, augmented_labels))\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, labels, test_size=0.2, random_state=42)\n",
    "final_train_images, val_images, final_train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "070745e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f932f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Keras Sequential API\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb78bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
